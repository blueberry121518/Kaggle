{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9142054,"sourceType":"datasetVersion","datasetId":5521547}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Cancer is a serious matter that changes people's lives forever. Thankfully, modern medicine provides techniques to identify and diagnose cancer cells. However, many people discover these signs a little too late and are unable to be saved. The creation of machine learning models allows people to check for signs of skin cancer quickly and easily. \nIn this notebook, I will use a dataset containing 270 images of benign and malignant images of skin cancer to train a model that can distinguish skin lesions as cancerous or normal. ","metadata":{}},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras import layers, models\n\n# Split files into benign and malignant\nbenign_image_filenames = []\nmalignant_image_filenames = []\nfor dirname, cancer, filenames in os.walk('/kaggle/input/skin-cancer-dataset/train_cancer'):\n    for filename in filenames:\n        if os.path.basename(dirname) == \"benign\":\n            benign_image_filenames.append(os.path.join(dirname, filename))\n        else:\n            malignant_image_filenames.append(os.path.join(dirname, filename))\n\n# Display the number of benign and malignant images\nprint(\"Benign: \" + str(len(benign_image_filenames)))\nprint(\"Malignant: \" + str(len(malignant_image_filenames)))\n\n# Display the first few image filenames\nprint(benign_image_filenames[:5])  \nprint(malignant_image_filenames[:5]) \n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-30T08:23:14.140260Z","iopub.execute_input":"2024-09-30T08:23:14.140707Z","iopub.status.idle":"2024-09-30T08:23:29.831032Z","shell.execute_reply.started":"2024-09-30T08:23:14.140662Z","shell.execute_reply":"2024-09-30T08:23:29.829902Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Benign: 30\nMalignant: 240\n['/kaggle/input/skin-cancer-dataset/train_cancer/benign/20.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/benign/6.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/benign/30.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/benign/38.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/benign/42.jpg']\n['/kaggle/input/skin-cancer-dataset/train_cancer/malignant/45.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/malignant/56.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/malignant/89.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/malignant/20.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/malignant/212.jpg']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"After splitting the images, I decided to normalize the pixels so that the machine learning model isn't overly affected by differences in lighting between images. Also this way, the range is scaled down so that it doesn't overshadow other features.","metadata":{}},{"cell_type":"code","source":"# Normalize images\nmalignant_normalized_images = []\nbenign_normalized_images = []\nfor image in benign_image_filenames:\n    with Image.open(image) as img:\n        img_array = np.array(img)  # Convert image to NumPy array\n        normalized_img = img_array / 255.0  # Normalize to [0, 1]\n        benign_normalized_images.append(normalized_img)\n        \nfor image in malignant_image_filenames:\n    with Image.open(image) as img:\n        img_array = np.array(img)  # Convert image to NumPy array\n        normalized_img = img_array / 255.0  # Normalize to [0, 1]\n        malignant_normalized_images.append(normalized_img)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T08:23:29.833010Z","iopub.execute_input":"2024-09-30T08:23:29.833628Z","iopub.status.idle":"2024-09-30T08:23:31.762200Z","shell.execute_reply.started":"2024-09-30T08:23:29.833582Z","shell.execute_reply":"2024-09-30T08:23:31.760871Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"While there are 240 images, I decided that 30 benign images isn't enough to train an accurate model. I decided to augment the existing images to create more unique images that can help the model. ","metadata":{}},{"cell_type":"code","source":"# Function that augments a list of images\ndef augment(images):\n        # Initialize the ImageDataGenerator\n    datagen = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest'\n    )\n\n    # Augmented images per original\n    num_augmented_images = 2\n\n    # Store augmented images\n    augmented_images = []\n\n    # Generate augmented images\n    for image in images:\n        image = image.reshape((1,) + image.shape)\n        for _ in range(num_augmented_images):\n            for augmented_image in datagen.flow(image, batch_size=1):\n                augmented_images.append(augmented_image[0]) \n                break \n\n    return np.array(augmented_images)\nbenign_augmented_images = augment(benign_normalized_images)\nmalignant_augmented_images = augment(malignant_normalized_images)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T08:23:31.763676Z","iopub.execute_input":"2024-09-30T08:23:31.764062Z","iopub.status.idle":"2024-09-30T08:23:38.833335Z","shell.execute_reply.started":"2024-09-30T08:23:31.764026Z","shell.execute_reply":"2024-09-30T08:23:38.832042Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Next, I needed to split the data into training and test sets. The augmented data all goes into the training data to improve model accuracy. ","metadata":{}},{"cell_type":"code","source":"# Split the original images into training and testing sets\nbenign_normalized_images = np.array(benign_normalized_images)  # Original benign images\nmalignant_normalized_images = np.array(malignant_normalized_images)  # Original malignant images\n \nX_train_benign, X_test_benign = train_test_split(benign_normalized_images, test_size=0.2, random_state=42)\nX_train_malignant, X_test_malignant = train_test_split(malignant_normalized_images, test_size=0.2, random_state=42)\n\n# Create labels for the test set\ny_test_benign = np.zeros(X_test_benign.shape[0])  # Label 0 for benign\ny_test_malignant = np.ones(X_test_malignant.shape[0])  # Label 1 for malignant\n\n# Combine test data and labels\nX_test = np.concatenate((X_test_benign, X_test_malignant), axis=0)\ny_test = np.concatenate((y_test_benign, y_test_malignant), axis=0)\n\n# Combine training set with augmented images\nall_benign_train = np.concatenate((X_train_benign, benign_augmented_images), axis=0)\nall_malignant_train = np.concatenate((X_train_malignant, malignant_augmented_images), axis=0)\n\n# Training Set Labels\nbenign_labels_train = np.zeros(all_benign_train.shape[0])  # Label 0 for benign\nmalignant_labels_train = np.ones(all_malignant_train.shape[0])  # Label 1 for malignant\n\n# Combine\nX_train = np.concatenate((all_benign_train, all_malignant_train), axis=0)\ny_train = np.concatenate((benign_labels_train, malignant_labels_train), axis=0)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T08:23:38.835859Z","iopub.execute_input":"2024-09-30T08:23:38.836345Z","iopub.status.idle":"2024-09-30T08:23:39.871539Z","shell.execute_reply.started":"2024-09-30T08:23:38.836296Z","shell.execute_reply":"2024-09-30T08:23:39.870461Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"I decided to use the pre-trained ResNet model because of it's good performance with image-related tasks. Then, I added two layers to it to reduce dimensionality and then to binarize the output data. ","metadata":{}},{"cell_type":"code","source":"# ResNet Model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Freeze the base model\nbase_model.trainable = False\n\n# Create sequentials layers\nmodel = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(1, activation='sigmoid') \n])\n\n# Compile\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_train, y_train),\n    epochs=4,  \n    batch_size=16\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T08:23:39.872774Z","iopub.execute_input":"2024-09-30T08:23:39.873113Z","iopub.status.idle":"2024-09-30T08:31:29.369344Z","shell.execute_reply.started":"2024-09-30T08:23:39.873080Z","shell.execute_reply":"2024-09-30T08:31:29.368165Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\nEpoch 1/4\n\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - accuracy: 0.8919 - loss: 0.3741 - val_accuracy: 0.8889 - val_loss: 0.3477\nEpoch 2/4\n\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.8722 - loss: 0.3843 - val_accuracy: 0.8889 - val_loss: 0.3547\nEpoch 3/4\n\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.8889 - loss: 0.3517 - val_accuracy: 0.8889 - val_loss: 0.3460\nEpoch 4/4\n\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.8834 - loss: 0.3599 - val_accuracy: 0.8889 - val_loss: 0.3494\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Model evaluation using the test data","metadata":{}},{"cell_type":"code","source":"# Model Evaluation\nval_loss, val_accuracy = model.evaluate(X_test, y_test)\nprint(f'Validation loss: {val_loss}, Validation accuracy: {val_accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T08:34:19.931949Z","iopub.execute_input":"2024-09-30T08:34:19.932442Z","iopub.status.idle":"2024-09-30T08:34:24.281876Z","shell.execute_reply.started":"2024-09-30T08:34:19.932377Z","shell.execute_reply":"2024-09-30T08:34:24.280786Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.8634 - loss: 0.4095\nValidation loss: 0.34916260838508606, Validation accuracy: 0.8888888955116272\n","output_type":"stream"}]}]}