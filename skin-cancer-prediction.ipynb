{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80c0967e",
   "metadata": {
    "papermill": {
     "duration": 0.004133,
     "end_time": "2024-09-30T05:06:07.974080",
     "exception": false,
     "start_time": "2024-09-30T05:06:07.969947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Cancer is a serious matter that changes people's lives forever. Thankfully, modern medicine provides techniques to identify and diagnose cancer cells. However, many people discover these signs a little too late and are unable to be saved. The creation of machine learning models allows people to check for signs of skin cancer quickly and easily. \n",
    "In this notebook, I will use a dataset containing 270 images of benign and malignant images of skin cancer to train a model that can distinguish skin lesions as cancerous or normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b200abe1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-30T05:06:07.982473Z",
     "iopub.status.busy": "2024-09-30T05:06:07.982065Z",
     "iopub.status.idle": "2024-09-30T05:06:22.302097Z",
     "shell.execute_reply": "2024-09-30T05:06:22.300753Z"
    },
    "papermill": {
     "duration": 14.327162,
     "end_time": "2024-09-30T05:06:22.304597",
     "exception": false,
     "start_time": "2024-09-30T05:06:07.977435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign: 30\n",
      "Malignant: 240\n",
      "['/kaggle/input/skin-cancer-dataset/train_cancer/benign/20.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/benign/6.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/benign/30.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/benign/38.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/benign/42.jpg']\n",
      "['/kaggle/input/skin-cancer-dataset/train_cancer/malignant/45.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/malignant/56.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/malignant/89.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/malignant/20.jpg', '/kaggle/input/skin-cancer-dataset/train_cancer/malignant/212.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Split files into benign and malignant\n",
    "benign_image_filenames = []\n",
    "malignant_image_filenames = []\n",
    "for dirname, cancer, filenames in os.walk('/kaggle/input/skin-cancer-dataset/train_cancer'):\n",
    "    for filename in filenames:\n",
    "        if os.path.basename(dirname) == \"benign\":\n",
    "            benign_image_filenames.append(os.path.join(dirname, filename))\n",
    "        else:\n",
    "            malignant_image_filenames.append(os.path.join(dirname, filename))\n",
    "\n",
    "# Display the number of benign and malignant images\n",
    "print(\"Benign: \" + str(len(benign_image_filenames)))\n",
    "print(\"Malignant: \" + str(len(malignant_image_filenames)))\n",
    "\n",
    "# Display the first few image filenames\n",
    "print(benign_image_filenames[:5])  \n",
    "print(malignant_image_filenames[:5]) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600c7df",
   "metadata": {
    "papermill": {
     "duration": 0.003154,
     "end_time": "2024-09-30T05:06:22.311362",
     "exception": false,
     "start_time": "2024-09-30T05:06:22.308208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After splitting the images, I decided to normalize the pixels so that the machine learning model isn't overly affected by differences in lighting between images. Also this way, the range is scaled down so that it doesn't overshadow other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e2b14c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T05:06:22.320042Z",
     "iopub.status.busy": "2024-09-30T05:06:22.319291Z",
     "iopub.status.idle": "2024-09-30T05:06:24.732737Z",
     "shell.execute_reply": "2024-09-30T05:06:24.731585Z"
    },
    "papermill": {
     "duration": 2.420596,
     "end_time": "2024-09-30T05:06:24.735259",
     "exception": false,
     "start_time": "2024-09-30T05:06:22.314663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize images\n",
    "malignant_normalized_images = []\n",
    "benign_normalized_images = []\n",
    "for image in benign_image_filenames:\n",
    "    with Image.open(image) as img:\n",
    "        img_array = np.array(img)  # Convert image to NumPy array\n",
    "        normalized_img = img_array / 255.0  # Normalize to [0, 1]\n",
    "        benign_normalized_images.append(normalized_img)\n",
    "        \n",
    "for image in malignant_image_filenames:\n",
    "    with Image.open(image) as img:\n",
    "        img_array = np.array(img)  # Convert image to NumPy array\n",
    "        normalized_img = img_array / 255.0  # Normalize to [0, 1]\n",
    "        malignant_normalized_images.append(normalized_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead7cd8",
   "metadata": {
    "papermill": {
     "duration": 0.003049,
     "end_time": "2024-09-30T05:06:24.741862",
     "exception": false,
     "start_time": "2024-09-30T05:06:24.738813",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "While there are 240 images, I decided that 30 benign images isn't enough to train an accurate model. I decided to augment the existing images to create more unique images that can help the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df03459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T05:06:24.750162Z",
     "iopub.status.busy": "2024-09-30T05:06:24.749468Z",
     "iopub.status.idle": "2024-09-30T05:06:31.372491Z",
     "shell.execute_reply": "2024-09-30T05:06:31.371283Z"
    },
    "papermill": {
     "duration": 6.629944,
     "end_time": "2024-09-30T05:06:31.375035",
     "exception": false,
     "start_time": "2024-09-30T05:06:24.745091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function that augments a list of images\n",
    "def augment(images):\n",
    "        # Initialize the ImageDataGenerator\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    # Augmented images per original\n",
    "    num_augmented_images = 2\n",
    "\n",
    "    # Store augmented images\n",
    "    augmented_images = []\n",
    "\n",
    "    # Generate augmented images\n",
    "    for image in images:\n",
    "        image = image.reshape((1,) + image.shape)\n",
    "        for _ in range(num_augmented_images):\n",
    "            for augmented_image in datagen.flow(image, batch_size=1):\n",
    "                augmented_images.append(augmented_image[0]) \n",
    "                break \n",
    "\n",
    "    return np.array(augmented_images)\n",
    "benign_augmented_images = augment(benign_normalized_images)\n",
    "malignant_augmented_images = augment(malignant_normalized_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df75159",
   "metadata": {
    "papermill": {
     "duration": 0.003102,
     "end_time": "2024-09-30T05:06:31.381671",
     "exception": false,
     "start_time": "2024-09-30T05:06:31.378569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, I needed to split the data into training and test sets. The augmented data all goes into the training data to improve model accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d15df3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T05:06:31.389912Z",
     "iopub.status.busy": "2024-09-30T05:06:31.389483Z",
     "iopub.status.idle": "2024-09-30T05:06:32.388567Z",
     "shell.execute_reply": "2024-09-30T05:06:32.387389Z"
    },
    "papermill": {
     "duration": 1.005993,
     "end_time": "2024-09-30T05:06:32.390970",
     "exception": false,
     "start_time": "2024-09-30T05:06:31.384977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the original images into training and testing sets\n",
    "benign_normalized_images = np.array(benign_normalized_images)  # Original benign images\n",
    "malignant_normalized_images = np.array(malignant_normalized_images)  # Original malignant images\n",
    " \n",
    "X_train_benign, X_test_benign = train_test_split(benign_normalized_images, test_size=0.2, random_state=42)\n",
    "X_train_malignant, X_test_malignant = train_test_split(malignant_normalized_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create labels for the test set\n",
    "y_test_benign = np.zeros(X_test_benign.shape[0])  # Label 0 for benign\n",
    "y_test_malignant = np.ones(X_test_malignant.shape[0])  # Label 1 for malignant\n",
    "\n",
    "# Combine test data and labels\n",
    "X_test = np.concatenate((X_test_benign, X_test_malignant), axis=0)\n",
    "y_test = np.concatenate((y_test_benign, y_test_malignant), axis=0)\n",
    "\n",
    "# Combine training set with augmented images\n",
    "all_benign_train = np.concatenate((X_train_benign, benign_augmented_images), axis=0)\n",
    "all_malignant_train = np.concatenate((X_train_malignant, malignant_augmented_images), axis=0)\n",
    "\n",
    "# Training Set Labels\n",
    "benign_labels_train = np.zeros(all_benign_train.shape[0])  # Label 0 for benign\n",
    "malignant_labels_train = np.ones(all_malignant_train.shape[0])  # Label 1 for malignant\n",
    "\n",
    "# Combine\n",
    "X_train = np.concatenate((all_benign_train, all_malignant_train), axis=0)\n",
    "y_train = np.concatenate((benign_labels_train, malignant_labels_train), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9237c46a",
   "metadata": {
    "papermill": {
     "duration": 0.003098,
     "end_time": "2024-09-30T05:06:32.397910",
     "exception": false,
     "start_time": "2024-09-30T05:06:32.394812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I decided to use the pre-trained ResNet model because of it's good performance with image-related tasks. Then, I added two layers to it to reduce dimensionality and then to binarize the output data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b02d8618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T05:06:32.406700Z",
     "iopub.status.busy": "2024-09-30T05:06:32.405798Z",
     "iopub.status.idle": "2024-09-30T05:15:43.903146Z",
     "shell.execute_reply": "2024-09-30T05:15:43.901942Z"
    },
    "papermill": {
     "duration": 551.504154,
     "end_time": "2024-09-30T05:15:43.905596",
     "exception": false,
     "start_time": "2024-09-30T05:06:32.401442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Epoch 1/4\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.8663 - loss: 0.3957 - val_accuracy: 0.8889 - val_loss: 0.3463\n",
      "Epoch 2/4\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - accuracy: 0.8876 - loss: 0.3534 - val_accuracy: 0.8889 - val_loss: 0.3533\n",
      "Epoch 3/4\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.8854 - loss: 0.3657 - val_accuracy: 0.8889 - val_loss: 0.3454\n",
      "Epoch 4/4\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.8905 - loss: 0.3461 - val_accuracy: 0.8889 - val_loss: 0.3455\n"
     ]
    }
   ],
   "source": [
    "# ResNet Model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create sequentials layers\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_train, y_train),\n",
    "    epochs=4,  \n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a130ec6",
   "metadata": {
    "papermill": {
     "duration": 0.019718,
     "end_time": "2024-09-30T05:15:43.945651",
     "exception": false,
     "start_time": "2024-09-30T05:15:43.925933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model evaluation using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf19668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T05:15:43.987460Z",
     "iopub.status.busy": "2024-09-30T05:15:43.987044Z",
     "iopub.status.idle": "2024-09-30T05:16:40.089317Z",
     "shell.execute_reply": "2024-09-30T05:16:40.088107Z"
    },
    "papermill": {
     "duration": 56.125883,
     "end_time": "2024-09-30T05:16:40.091593",
     "exception": false,
     "start_time": "2024-09-30T05:15:43.965710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.6765 - loss: 0.8137\n",
      "Validation loss: 0.3454526364803314, Validation accuracy: 0.8888888955116272\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "val_loss, val_accuracy = model.evaluate(X_train, y_train)\n",
    "print(f'Validation loss: {val_loss}, Validation accuracy: {val_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5521547,
     "sourceId": 9142054,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 637.714668,
   "end_time": "2024-09-30T05:16:43.124339",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-30T05:06:05.409671",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
